
\chapter{Conclusion and Future Work}\label{sec:conclusion_and_future_work}
To conclude this work, we summarize the presented models, algorithms, implementations, studies and the main findings. Moreover, we give an outlook on future work and additional research questions that can be approached building on our work.

\section{Summary of this Work}

The overarching goal of this work was to enable simulations of the neuromuscular system using detailed, biophysical multi-scale models with high resolutions. The simulations should compute numerically accurate results, run efficiently on various hardware and allow parallel scaling to large problem sizes, which should be solved on supercomputers.

As a result, this work established a computational framework for multi-scale modeling of skeletal muscles, their neural activation, muscle contraction and generation of EMG signals on the skin surface. Our approach combined existing models for various parts of the neuromuscular system into a comprehensive multi-scale model framework. Scalability and parallel efficiency of our software were ensured by efficient algorithms, suitable, parallelized numerical schemes and by our accompanying performance analyses.

% ieser Arbeit war ... biophysikalisch, hoch aufgelöst, schnell, skalierbar, genau ...

We described the following topics in this work: After the introduction in \cref{chap:introduction}, we compared two modeling approaches to describe the movement of the upper arm in \cref{chap:comparative_study}. Based on data of experimental trials we conducted during a graduate school workshop, we developed a first, data-driven model using Gaussian process regression and a second model based on a biophysical simulation with two muscle models. The parameters for the biophysical simulation were fitted to experimental training data using numerical optimization. The comparison of the two approaches revealed a slightly better fit for the biophysical simulation model. This approach had the additional benefit of giving biophysical insights into the functioning of the system and provided estimates for subject-specific muscle parameters. While this study used Hill-type muscle models, which describe muscle forces on a 1D line of action, we considered more accurate multi-scale models in the remainder of this work.

\Cref{sec:generation_of_meshes_for_multiscale} dealt with the generation of structured 3D meshes and embedded 1D meshes for muscle fibers. The approach of only using structured meshes, which allowed for a simple domain decomposition proved to be beneficial for the parallel performance of our simulations.  
We described a workflow, how to obtain these meshes from biomedical imaging data. We developed a serial algorithm and a parallel algorithm to construct the required meshes and to ensure a good mesh quality, even for meshes with high resolutions. The algorithms were based on our novel approach of using harmonic maps to transform reference meshes to cross-sectional slices of the muscle mesh.

In \cref{sec:muscle_fibers_and_motor_units}, we described ways to associate muscle fibers with motor units (MUs) in a physiological manner. We developed efficient algorithms for this task for different premises, and employed the algorithms to associate up to \num{270000} muscle fibers to \num{100} MUs for the subsequent use in our simulations.

In \cref{chap:models_and_discretization}, we first described all equations of the state-of-the models that we used, and how they can be combined into a multi-scale description. Then, we described their discretization using the finite element method for the spatial derivative terms and various timestepping and operator splitting schemes for the temporal derivatives. One original contribution is the derivation of the finite element formulation for the multidomain equation. Further, we gave a detailed description of the nonlinear solid mechanics discretization, which we used in our implementation.

Next, we presented details on our simulation software OpenDiHu, which we used to solve various combinations of the described multi-scale model framework to simulate the neuromuscular system. \Cref{chap:usage} gave an introduction to the design and usage of the software and demonstrated its application using various example problems.

\Cref{sec:implementation} described the implementation of OpenDiHu in more detail, motivated various design decisions, introduced the data handling and several algorithms, e.g., to construct a parallel domain decomposition or to map data between meshes, and described the implementation of various solvers for particular parts of the multi-scale model.

\Cref{sec:results} presented numerical results, which were obtained using our simulation software. We simulated the passive mechanical behavior of muscle tissue, subcellular models given in CellML description, electrophysiology on muscle fibers, electric conduction in the muscle and the adipose tissue to obtain surface EMG signals, electrophysiology using the 3D homogenized multidomain description, and coupled scenarios of electrophysiology and muscle contraction. We discussed effects of model and structural parameters and interpreted the obtained simulation results.

In \cref{sec:performance_analysis}, we analyzed the computational performance of our software in general and various solvers in particular. We conducted numerical studies of universal convergence properties with the software OpenCMISS, which also helped to parameterize the numerical solvers in OpenDiHu. Further studies on mesh widths and used linear solvers were carried out directly using OpenDiHu. We evaluated various optimization options in OpenDiHu and compared the most optimized settings in OpenDiHu with the baseline solver OpenCMISS, yielding a high speedup of more than two orders of magnitude. Moreover, we investigated the computational performance of our models on the GPU, and conducted parallel strong scaling and parallel weak scaling tests on small clusters and the supercomputers at the High Performance Computing Center Stuttgart.

\section{Summary of Main Findings}

The present work simulated numerous scenarios with various model combinations, which provided different insights. In the following, we summarize the observed findings. We address the biophysical observations in \cref{sec:observations_biophysics} and results of the performance measurements in \cref{sec:observations_performance}.

\subsection{Observations from the Fields of Biophysics and Biomechanics}\label{sec:observations_biophysics}
The comparison of the linear and nonlinear mechanics models in \cref{sec:solver_solid_mechanics} showed qualitatively different results and demonstrated that the accurate behavior of deforming muscle tissue can only be described by a proper nonlinear anisotropic solid mechanics model. 

Initially, an open question was also how to relate the accuracy of the simulated EMG signals to the number of fibers and the mesh resolution. Our numerical studies in \cref{sec:action_potential_velocity}, which compared the resulting action propagation velocity for different mesh widths of the 1D muscle fiber meshes showed that a mesh width of \SI{100}{\micro\meter} or 100 elements per \SI{}{\centi\meter} gives reasonably accurate results. 

To evaluate the 3D mesh width and the spacing between the muscle fibers, we conducted simulations with different 3D mesh resolutions and numbers of fibers in \cref{sec:effects_of_the_mesh_width_emg}. The number of fibers was scaled up to the realistic number of \num{270000} fibers in a biceps brachii muscle. We concluded that the most accurate solution is obtained for a mesh width as fine as possible, as the EMG results were qualitatively different for every refinement step. This emphasizes the need for highly resolved simulation scenarios (representing the real number of fibers in a muscle accurately) for realistic EMG computations and, as a result, the need for High Performance Computing techniques.

However, if the EMG is to be sampled by electrodes, i.e., if the EMG recording process should also be part of the simulation, lower mesh widths might be possible, as the EMG is only captured at the locations of the electrodes.

One possible approach to reduce the computational effort for EMG simulations would be to only consider the muscle tissue down to a certain depth below the surface with the EMG electrodes. We observed in \cref{sec:simfiber_mu}, that the EMG signal is highly influenced by MUs, whose territories are located close to the electrodes. However, our numerical experiments with EMG decomposition algorithms in \cref{sec:simfiber_decomposition} showed that large MUs located opposite to the EMG electrodes at the deepest muscle tissue layers are detectable in the surface EMG signals. Thus, neglecting the deeper parts of the muscle would remove relevant information from the system and is, therefore, not a valid approach to reduce the computational load.

Furthermore, the layer of adipose tissue on top of the muscle showed a smoothing effect on EMG recordings in our simulations, both with the fiber based approach in \cref{sec:simfiber_fat} and with the multidomain approach in \cref{sec:multidomain_components,sec:multidomain_simulation_emg}. One advantage of our simulations compared to experimental studies is that the thickness of the fat layer is known exactly and can also be adjusted.

Simulations of muscle contraction with coupled electrophysiology and solid mechanics models showed a spatially inhomogeneous contraction  for the biceps muscle while the muscle activation is ramped up. The simulation in \cref{sec:fiber_based_contraction} of an isolated, contracting muscle belly without tendons showed transverse bending, alternating between the left and right-hand sides, as a result of the subsequently activated MUs at the different sides of the muscle. We also simulated the biceps brachii muscle together with its tendons and observed a ripple in the generated muscle force, which is caused by the same inhomogeneous MU activity.

The simulations of muscle contraction also showed that, if the muscle is initially in a stress-free state, the model can only achieve a maximum contraction of approximately \SI{85}{\percent}. However, the muscles of the musculoskeletal system are known to exhibit prestresses in their relaxed states. Accordingly, we added prestress to our simulations. The amount of prestress is adjustable in the simulation settings, and the required amount can be determined by a comparison with experimental studies.

% linear-nonlin
% accuracy -> high mesh resolution
% fibers: effects of fat mesh, distance between fibers to surface, size of MUs (EMG decomposition)
% multidomain: more smoothed
% coupled solid mechanics: inhomogeneous contraction, prestretch required (without only 85% contraction)

\section{Summary of Performance Results}\label{sec:observations_performance}

A major part of the work was also concerned with improving the performance of the simulation software, and, thus, enabling larger simulation scenarios in shorter runtimes.

Previously, literature on biophysical, multi-scale models of skeletal muscles was mainly focused on modelling and interpretation of the results, rather than targeting efficient computations. The work of Röhrle et al. \cite{Roehrle2012} introduced the multi-scale model, which we based our work on, and simulated the tibialis anterior muscle using a 3D mechanics mesh with 12 elements. The work of Heidlauf et al. \cite{Heidlauf2013} considered the same geometry and simulated 400 muscle fibers. The authors parallelized their OpenCMISS based implementation for a fixed number of four processes. We built upon this work with the goal to push the limits of feasible problem sizes, and, in \cref{sec:effects_of_the_mesh_width_emg}, executed our optimized simulation with \num{26912} processes, \num{273529} muscle fibers and a 3D mesh for the electrophysiology model with approximately \num{1e8} degrees of freedom.

The performance analyzes in \cref{sec:performance_analysis} showed that the subcellular model contributes a large portion to the total runtime and, thus, is the most crucial part to optimize. By using proper memory layouts, vectorization is possible. Our approach of using explicit vector instructions outperformed the auto-vectorization capabilities of the compiler. The approximation of the exponential function and an improved parallelization scheme for the 1D electric conduction problem additionally contributed to a high speedup. The comparison to the baseline solver OpenCMISS Iron in a strong scaling study in \cref{sec:strong_scaling_runtimes_opencmiss_opendihu} revealed a maximum speedup of 363 for the purely implementation-specific improvements and an additional speedup of 2.5, shown in \cref{sec:opencmiss_numeric_improvements}, by using more efficient numerical methods.

In addition, the memory characteristics of the solvers were investigated in \cref{sec:strong_scaling_runtimes_opencmiss_opendihu}. 
The linear increase in memory consumption of the baseline solver in a weak scaling setting was improved to a nearly constant scaling. Our analysis using a roofline performance model showed that our solvers are compute bound and achieve a computational performance of approximately \SI{25}{\percent} peak performance, which is a very good value.

Moreover, hybrid shared/distributed memory parallelism and computations on the GPU were investigated, but both approaches were found to be not competitive with our highly optimized distributed memory parallelization. For the GPU, potentially more efficient approaches than our approach using OpenMP exist, such that a performance improvement in the future could be possible.

The modularity of the CellML infrastructure, where computational models can be shared among researchers and are interchangeable in multi-scale simulations was preserved during all optimization endeavors. Our approach was to implement a source-to-source code generator, which transformed the given CellML code into optimized code for the CPU or the GPU.

For the solution of the multidomain model, we evaluated various preconditioners and selected the most performant preconditioner-solver combination for our computations.
One previously unforeseen result is the large discrepancy of required runtime between the fiber based and the multidomain based electrophysiology models, presented in \cref{sec:solver_multidomain_model}. We measured by a factor of 1000 longer computation times for the multidomain model, which result from the structure of the model. Despite the high computational effort, the multidomain model is useful in practice as it can simulate effects that are not captured by the fiber based model. We gave a detailed comparison between both approaches in \cref{sec:multidomain_differences}.

In summary, we provided a computationally efficient and scalable tool for applied biophysics researchers to solve problems in the domains of EMG generation and muscle contraction. For example, the effect of different muscle fiber organizations and MU recruitment strategies can be tested with our software. We demonstrated its use with state-of-the-art EMG decomposition algorithms, which provide the bridge to the experimental domain.
Thus, we hope to contribute one step on the pathway of complementing in vivo with in silico experiments to increase the understanding of the neuromuscular system.

% provide a tool for applied biophysics researchers
% --------------------
% complement in-vivo and in-silico experiments
% test different muscle fiber organizations -> possible
% decomposition of EMG -> tested


% vc better than auto-vec, AVX-512, memory layout
% comparison to OpenCMISS
% preserve CellML modularity -> code generator
% GPU, OpenMP
% proper choice of solvers
% multidomain performance vs fibers


% performance
% --------------
% Röhrle2012: TA 12 elements, MU association
% Heidlauf2013: 400 fibers, TA, OpenCMISS, mechanics
% made new insights possible  


%wir hatten ja mal vorgenommen dass
%tatsächlich ist gelungen:
%überraschenderweise, dass: 

%bewerten mit den Ergebnissen
%was bewahrheitet, 

%unterschiede zwischen grob und hochaufgelöster Sim
%anzahl realitäts anzahl Muskelfaser anzahl

\section{Outlook and Future Work}\label{sec:future_work}
 
The presented work could be extended in multiple directions, spanning performance improvements and model extensions.

First, some ideas for further performance improvements could be implemented and evaluated. 
The monodomain equation could be solved with implicit-explicit (IMEX) schemes, which could potentially achieve higher precision. 
The numerically stiff subcellular model is currently solved explicitly. Implicit schemes could be developed, and the implicit iteration equations could be solved symbolically in a preprocessing step using the parsed CellML code. 

To improve the performance of the multidomain model, the following algorithmic improvements are promising options. 
The 3D problems of action potential propagation in the muscle volume for every compartment could be restricted to the subset of nodes, where the occupancy factors are above a certain threshold, effectively reducing the problem sizes, and reducing the effect of higher MU counts on the runtime. However, this would bring difficulties to ensure a balanced parallel domain decomposition.
Instead of the current parallel partitioning of the domain, the multidomain model could also be parallelized by distributing the MUs to different processes or by a combination of both approaches.

On the numerical side, an extended error analysis could be carried out for all model parts, and the timestep widths, which are currently chosen conservatively, could potentially be increased, while keeping the numerical error below a given threshold. Error estimators could be developed, which would allow an adaptive adjustment of the timestep widths.
The 3D model solvers for the 3D electrophysiology and multidomain problems could be enhanced with geometric or algebraic multigrid preconditioners.

Since all subcellular points in a muscle are usually in similar states at any time, a hybrid approach using analytic descriptions of action potential propagation, as in \cref{sec:sim_rosenfalck}, and a fully numerical treatment could be chosen, and surrogate models could be adaptively added to the computational description.

On the technical side, computations on the GPU could be re-evaluated in the future using the existing OpenMP approach with more mature compiler versions or different accelerator targeting programming technologies.

Second, the range of simulated models could be extended. The simulations could be applied to further muscle geometries such as the triceps brachii or the tibialis anterior muscles. Muscles with more complex geometries and fiber arrangements could be investigated. 
A mechanically coupled problem of agonist-antagonist pair could be considered such as a system of biceps and triceps brachii. Apart from the mechanical coupling, a coupling of the neural recruitment involving sensory organs in the muscles could be implemented and used to approach further biomechanical research questions. Such a neuromuscular feedback loop could also be investigated first for a single muscle, e.g., by extending the preliminary implementation in OpenDiHu for the biceps muscle.

Pathological conditions could be simulated to understand muscular diseases and neuromuscular electrical stimulation of the muscle for stroke rehabilitation could be considered.

By using the preCICE adapters in OpenDiHu, more advanced mechanics solvers could be coupled to an electrophysiology simulation in OpenDiHu, allowing to, e.g., study mechanical effects of surrounding tissue.

On a larger scale, the interplay of more organs could be taken into account. Blood perfusion and muscle metabolism could be added, and coupled by models of the lung and general metabolism in the organism. Thus, a digital human model can be envisioned, which allows to study the effects of anomalies and to develop new therapies, effectively utilizing simulation technology for human wellbeing.

%reduced to 1D problems using appropriate transformations.


% performance improvements
% ----------------------------
% more timestepping methods: CVODE (https://computing.llnl.gov/projects/sundials/cvode), imex
% different parallelisation where not all ranks have to be involved (for multidomain) -> this feature already exists for the fibers with multipleInstances
% more numeric tests on exp function? no
% multidomain: compute 3D problem as 1D problem, or adaptive computation of the parts of the fr factors
% GPU

% extensions
% -------------
% other muscles, more muscles,
% couple more models:
% neuromuscular feedback loop with sensors, 
% 






